{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Task 1: Data Wrangling\n\n### Table of Contents\n\n1. [Introduction](#introduction)\n2. [Data Gathering](#data_gathering)\n3. [Data Assessing](#data_assessing)\n    * [Assessment Summary](#assessment_summary)\n4. [Data Cleaning](#data_cleaning)\n5. [Saving](#saving)"},{"metadata":{},"cell_type":"markdown","source":"## Introduction <a class=\"anchor\" id=\"introduction\"></a>\n\nData wrangling is performed on the Ames Housing dataset, which describes the features of residential homes in Ames, Iowa. The dataset is separated in two files, namely training set and testing set. Both training and testing sets have 79 columns describing the features of the homes, but training set has one additional column, which consists of the home prices. The explanation for each column can be found [here](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data).\n\nThe steps for data wrangling includes gathering, assessing, cleaning. Data wrangling is only performed on the training set only because testing set should be considered as unseen data. For gathering, data is only gathered from one source, which is the training set. Subsequently, data is assessed with visual and programmatic assessments to look for data quality and tidiness issues. Finally, data is cleaned based on the issues detected during assessment stage."},{"metadata":{},"cell_type":"markdown","source":"## Data Gathering <a class=\"anchor\" id=\"data_gathering\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import libraries\nimport os\nimport pandas as pd\nimport numpy as np\nimport math\npd.set_option('display.max_columns', None)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define URLs of training sets\ndirname = '/kaggle/input'\nsubdirname = 'house-prices-advanced-regression-techniques'\ntrain_filename = 'train.csv'\ntrain_filepath = os.path.join(dirname, subdirname, train_filename)\n\n# Load training and testing sets\ndf = pd.read_csv(train_filepath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print out the first 5 rows of df_train\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Training set: {}\".format(df.shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"## Data Assessing <a class=\"anchor\" id=\"data_accessing\"></a>\n\nData is assessed with visual and programmatic assessment to look for data quality and tidiness issues"},{"metadata":{},"cell_type":"markdown","source":"### Visual Assessment"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sample n rows at random from the data frame for visual assessment\nn_samples = 10\ndf.sample(n = n_samples)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Programmatic Assessment\n\n#### Step 1: Check if there are any duplicates"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for duplicates based on all columns\nprint(\"Number of duplicates: {}\".format(sum(df.duplicated())))\n\n# Check for duplicates based on all columns except 'Id'\ncolumns_without_id = list(df.columns)\ncolumns_without_id.remove('Id')\n\nprint(\"Number of duplicates (without 'Id'): {}\".format(sum(df.duplicated(subset=columns_without_id))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ##### Finding(s) for Step 1:\n> - There is no duplicate.\n\n\n#### Step 2: Determine the number of nulls/missing data and the correct datatypes"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check number of NaNs in each column and data type of each column\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ##### Finding(s) for Step 2:\n\n> - 80 variables (excld. ID)\n\n>> -  34 Numeric variables \n\n>>> -  14 discrete variables (YearBuilt, YearRemodAdd, BsmtFullBath, BsmtHalfBath, FullBath, HalfBath, BedroomAbvGr, KitchenAbvGr, TotRmsAbvGrd, Fireplaces, GarageYrBlt, GarageCars, MoSold, YrSold)\n\n>>> -  20 continuous variables (LotFrontage, LotArea, MasVnrArea, BsmtFinSF1, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF, 1stFlrSF, 2ndFlrSF, LowQualFinSF, GrLivArea, GarageArea, WoodDeckSF, OpenPorchSF, EnclosedPorch, 3SsnPorch, ScreenPorch, PoolArea, MiscVal, SalePrice)\n\n>> - 46 categorical variables \n\n>>> - 25 nominal variables (MSSubClass, MSZoning, Street, Alley, Utilities, LotConfig, Neighborhood, Condition1, Condition2, BldgType, HouseStyle, RoofStyle, RoofMatl, Exterior1st, Exterior2nd, MasVnrType, Foundation, Heating, CentralAir, Electrical, GarageType, PavedDrive, MiscFeature, SaleType, SaleCondition)\n\n>>> - 21 ordinal variables (LotShape, LandContour, LandSlope, OverallQual, OverallCond, ExterQual, ExterCond, BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2, HeatingQC, KitchenQual, Functional, FireplaceQu, GarageFinish, GarageQual, GarageCond, PoolQC, Fence)\n\n> - Wrong data types (MSSubClass) - should be string instead of integer\n\n> - Wrong data types (LotArea, 1stFlrSF, 2ndFlrSF, LowQualFinSF, GrLivArea, WoodDeckSF, OpenPorchSF, EnclosedPorch, 3SsnPorch, ScreenPorch, PoolArea, MiscVal) - should be float instead of integer\n\n> - Wrong data types (BsmtFullBath, BsmtHalfBath, GarageYrBlt) - should be integer instead of float\n\n> - 19 variables with nulls/missing data\n\n>> - 3 numeric variables (LotFrontage, MasVnrArea,  GarageYrBlt)\n\n>> - 16 categorical variables (Alley, MasVnrType, BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1,BsmtFinType2, Electrical, FireplaceQu, GarageType, GarageFinish, GarageQual, GarageCond, PoolQC, Fence, MiscFeature)\n\n#### Step 3: Investigate the missing data further\n\nBased on data_description_txt (can be found [here](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)), certain variables consist of nulls or NANs because these variables are not possessed by the house. For example, NAN for alley variable means that the house does not have alley access. Thus, null or NAN doesn't mean missing data for these variables. \n\n> ##### Finding(s) for Step 3: \n\n> - Nulls in 23 variables do not represent missing data \n\n>> - 9 numeric variable (BsmtFinSF1, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF, BsmtFullBath, BsmtHalfBath, GarageYrBlt, GarageCars, GarageArea)\n\n>> - 14 categorical variable (Alley, BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2, FireplaceQu, GarageType, GarageFinish, GarageQual, GarageCond, PoolQC, Fence, MiscFeature)\n\n#### Step 4: Look for any outliers in numeric variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute statistics of numeric variables\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ##### Finding(s) for Step 4:\n\n> - The data for numeric variables are pretty clean as there isn't any obvious outlier.\n\n#### Step 5: Look for any abnormal data in categorical variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define categorical variables\ncat_vars = ['MSSubClass', 'MSZoning', 'Street', 'Alley', 'Utilities', 'LotConfig', 'Neighborhood', 'Condition1', \n            'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', \n            'MasVnrType', 'Foundation', 'Heating', 'CentralAir', 'Electrical', 'GarageType', 'PavedDrive', \n            'MiscFeature', 'SaleType', 'SaleCondition', 'LotShape', 'LandContour', 'LandSlope', 'OverallQual', \n            'OverallCond', 'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', \n            'BsmtFinType2', 'HeatingQC', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageFinish', 'GarageQual',\n            'GarageCond', 'PoolQC', 'Fence']\n\n# Print the unique values for each categorical variable\nfor var in cat_vars:\n    # Get unique values\n    unique_vals = df[var].unique()\n \n    print(\"{} : {}\".format(var, unique_vals))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ##### Finding(s) for Step 5:\n\n> - After comparing the list of unique values of each variable with data_description_txt (can be found [here](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)), the data for categorical variables are pretty clean and only the following two data quality issues were found.\n\n>> - 'WdShing' in 'Exterior1st' variable is the same as 'Wd Shng' in 'Exterior2nd' variable. For consistency, 'Wd Shng' in 'Exterior2nd' should be renamed as 'WdShing'\n\n>> - 'BrkComm' in 'Exterior1st' variable is the same as 'Brk Cmn' in 'Exterior2nd' variable. For consistency, 'Brk Cmn' in 'Exterior2nd' should be renamed as 'BrkComm'\n\n#### Step 6: Look for any discrepancies in year variables\n\nThere are 4 variables that are related to year, namely YearBuilt, YearRemodAdd, GarageYrBlt and YrSold. \n\n- YearBuilt:  Original construction date\n- YearRemodAdd: Remodel date\n- GarageYrBlt: Year garage was built\n- YrSold: Year Sold\n\nThese 4 variables will be compared to ensure the chronological order of these variables is logical. YearBuilt should occur first, and YrSold should occur last. YearRemodAdd and GarageYrBlt should occur within YearBuilt and YrSold. Thus, the expected chronological order is YearBuilt -> YearRemodAdd/GarageYrBuilt -> YrSold\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define year variables\nyear_vars = ['YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'YrSold']\n\n# Select YearBuilt, YearRemodAdd, GarageYrBlt and YrSold from the data frame\ndf_year = df[year_vars]\n\n# Define a function to check the chronological order\ndef is_correct_order(x):\n    # Set 'YearRemodAdd' or 'YearGarageYrBlt' as 'YearBuilt if they are NaN because NaN will cause\n    # the condition for checking chronological order below to return False in any scenario.\n    if pd.isna(x['YearRemodAdd']):\n        x['YearRemodAdd'] = x['YearBuilt'] \n        \n    if pd.isna(x['GarageYrBlt']):\n        x['GarageYrBlt'] = x['YearBuilt'] \n    \n    # Check correctness of chronological order\n    if x['YearBuilt'] <= x['YearRemodAdd'] <= x['YrSold'] and x['YearBuilt'] <= x['GarageYrBlt'] <= x['YrSold']:\n        return True\n    else:\n        return False\n\n# Get row(s) whose chronological order is not logical\ndf_year[~(df_year.apply(is_correct_order, axis=1))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ##### Finding(s) for Step 6:\n\n> - For rows with ID of 523, YearRemodAdd doesn't occur between YearBuilt and YrSold. YearRemodAdd should be replaced with YearBuilt or YrSold, depending on which is closer to YearRemodAdd\n\n> - For rows with IDs of 29, 93, 324, 600, 736, 1103, 1376, 1414 and 1418, GarageYrBlt doesn't occur between YearBuilt and YrSold. GarageYrBlt should be replaced with YearBuilt or YrSold, depending on which is closer to GarageYrBlt\n\n#### Step 7: Check consistency in area (square feet)\n\nIf the data is correct, the following equations must be satisfied.\n\n- TotalBsmtSF = BsmtFinSF1 + BsmtFinSF2 + BsmtUnfSF\n- GrLivArea = 1stFlrSF + 2ndFlrSF + LowQualFinSF"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get the row(s) whose TotalBsmtSF = BsmtFinSF1 + BsmtFinSF2 + BsmtUnfSF is not satisfied\ndf[df['BsmtFinSF1'] + df['BsmtFinSF2'] + df['BsmtUnfSF'] != df['TotalBsmtSF']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get the row(s) whose GrLivArea = 1stFlrSF + 2ndFlrSF + LowQualFinSF is not satisfied\ndf[df['1stFlrSF'] + df['2ndFlrSF'] + df['LowQualFinSF'] != df['GrLivArea']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ##### Finding(s) for Step 7:\n\n> - Based on the results shown above, all the rows satisfy both 'TotalBsmtSF = BsmtFinSF1 + BsmtFinSF2 + BsmtUnfSF' and 'GrLivArea = 1stFlrSF + 2ndFlrSF + LowQualFinSF'\n\n#### Step 8: Look for variables with many nulls"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set the threshold for acceptable null percentage\nthreshold = 0.2\n\n# Print the variables that have null percentage greater than the threshold\ndf.loc[:, df.isnull().mean() > threshold].isnull().mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ##### Finding(s) for Step 8:\n\n> - There are 5 variables with null percentage that is greater than 0.2 or 20% - Alley, FireplaceQu, PoolQC, Fence and MiscFeature. As these variables have too many missing data, they will be dropped from the data frame."},{"metadata":{},"cell_type":"markdown","source":"### Assessment Summary <a class=\"anchor\" id=\"assessment_summary\"></a>\n\nBased on the findings above, the following data quality issues were detected.\n\n- Wrong data types (MSSubClass) - should be string instead of integer\n- Wrong data types (LotArea, 1stFlrSF, 2ndFlrSF, LowQualFinSF, GrLivArea, WoodDeckSF, OpenPorchSF, EnclosedPorch, 3SsnPorch, ScreenPorch, PoolArea, MiscVal) - should be float instead of integer\n- Wrong data types (BsmtFullBath, BsmtHalfBath, GarageYrBlt) - should be integer instead of float\n- Nulls in 23 variables do not represent missing data, but they means that these variables are not possessed by the house. Thus, nulls (if there are any) in these variables should be replaced with other string to indicate that these variables are not possessed by the house.\n> - 9 numeric variable (BsmtFinSF1, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF, BsmtFullBath, BsmtHalfBath, GarageYrBlt, GarageCars, GarageArea)\n> - 14 categorical variable (Alley, BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2, FireplaceQu, GarageType, GarageFinish, GarageQual, GarageCond, PoolQC, Fence, MiscFeature)\n\n- 'WdShing' in 'Exterior1st' variable is the same as 'Wd Shng' in 'Exterior2nd' variable. For consistency, 'Wd Shng' in 'Exterior2nd' should be renamed as 'WdShing'\n- 'BrkComm' in 'Exterior1st' variable is the same as 'Brk Cmn' in 'Exterior2nd' variable. For consistency, 'Brk Cmn' in 'Exterior2nd' should be renamed as 'BrkComm'\n- For rows with ID of 523, YearRemodAdd doesn't occur between YearBuilt and YrSold. YearRemodAdd should be replaced with YearBuilt or YrSold, depending on which is closer to YearRemodAdd\n- For rows with IDs of 29, 93, 324, 600, 736, 1103, 1376, 1414 and 1418, GarageYrBlt doesn't occur between YearBuilt and YrSold. GarageYrBlt should be replaced with YearBuilt or YrSold, depending on which is closer to GarageYrBlt\n- Alley, FireplaceQu, PoolQC, Fence and MiscFeature should be dropped from the data frame as they have too many missing data."},{"metadata":{},"cell_type":"markdown","source":"## Data Cleaning <a class=\"anchor\" id=\"data_cleaning\"></a>\n\nData is cleaned based on the assessment summary. There are three steps for each cleaning prcoess, which are define, code, test.\n\n- Define: define objective of the cleaning process\n- Code: write code for performing the objective\n- Test: verify cleaning process is carried out as intended\n\nBefore cleaning begins, a copy of the data frame is created. All the cleaning is performed on the copy, so that cleaned and uncleaned data frames can be compared if needed."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a copy of the data frame\ndf_clean = df.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Step 1: Change data types\n\n***Define***\n\n- Convert data type of MSSubClass from integer to string\n- Convert data types of LotArea, 1stFlrSF, 2ndFlrSF, LowQualFinSF, GrLivArea, WoodDeckSF, OpenPorchSF, EnclosedPorch, 3SsnPorch, ScreenPorch, PoolArea, MiscVal from integer to float*\n- Convert data types of BsmtFullBath, BsmtHalfBath from float to integer\n\n***Code***"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert data type of MSSubClass to string\ndf_clean['MSSubClass'] = df_clean['MSSubClass'].astype(str)\n\n# Convert data types of LotArea, 1stFlrSF, 2ndFlrSF, LowQualFinSF, GrLivArea, WoodDeckSF, \n# OpenPorchSF, EnclosedPorch, 3SsnPorch, ScreenPorch, PoolArea, MiscVal to float\n\ncolumns = ['LotArea', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'WoodDeckSF', 'OpenPorchSF', \n           'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal']\n\nfor col in columns:\n    df_clean[col] = df_clean[col].astype(float)\n    \n# Convert data types of BsmtFullBath, BsmtHalfBath to integer\ncolumns = ['BsmtFullBath', 'BsmtHalfBath', 'GarageYrBlt']\n\nfor col in columns:\n    df_clean[col] = df_clean[col].astype('Int64')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Test***"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['MSSubClass', 'LotArea', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', \n    'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', \n    'MiscVal', 'BsmtFullBath', 'BsmtHalfBath']].info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean[['MSSubClass', 'LotArea', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', \n          'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', \n          'MiscVal', 'BsmtFullBath', 'BsmtHalfBath']].info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Step 2: Replace nulls in 23 variables\n\n***Define***\n\nNulls in these 23 variables do not represent missing data, but they means that these variables are not possessed by the house. Out of 23 variables, 9 are numeric variables and 14 are categorical variables. Some of the variables are closely related to one anothers. For example, all the information about the garage of a house can be found from GarageYrBlt, GarageCars, GarageArea, GarageType, GarageFinish, GarageQual and GarageCond variables. If a house does not have a garage, then nulls in all the categorical variables that are related to garaga will be replaced with NoGarage. Whereas, nulls in all the numerical variables will be replaced with 0.\n\nWe can split all the 23 variables into 3 categories, which are:\n\n- Basement (BsmtFinSF1, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF, BsmtFullBath, BsmtHalfBath, BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2)\n- Garage (GarageYrBlt, GarageCars, GarageArea, GarageType, GarageFinish, GarageQual, GarageCond)\n- Others (Alley, FireplaceQu, PoolQC, Fence, MiscFeature)\n\nThe 3 categories will be cleaned separately with the sequence shown in the list above.\n\n***Code***"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Clean basement category\n\n# Define the variables that are related to basement\nvar_numerical = ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath']\nvar_categorical = ['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']\n\n# Get boolean index of rows for house without basement\nbool_index = df_clean[var_categorical].isnull().all(axis=1)\n\n# Replace numeric variables with 0\ndf_clean.loc[bool_index, var_numerical] = 0\n\n# Replace categorical variables with NoBsmt\ndf_clean.loc[bool_index, var_categorical] = 'NoBsmt'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Clean garage category\n\n# Define the variables that are related to garage\nvar_numerical = ['GarageYrBlt', 'GarageCars', 'GarageArea']\nvar_categorical = ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']\n\n# Get boolean index of rows for house without garage\nbool_index = df_clean[var_categorical].isnull().all(axis=1)\n\n# Replace numeric variables with 0\ndf_clean.loc[bool_index, var_numerical] = 0\n\n# Replace categorical variables with NoBsmt\ndf_clean.loc[bool_index, var_categorical] = 'NoGarage'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Clean other category\n\n# Define the variables in other category\nvar_categorical = ['Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature']\n\nfor var in var_categorical:\n    # Get boolean index of rows with nulls\n    bool_index = df_clean[var].isnull()\n    \n    # Replace categorical variables with No{Variable Name}\n    df_clean.loc[bool_index, var] = 'No{}'.format(var)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Test***"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean[['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'BsmtQual', 'BsmtCond', \n          'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'GarageType', \n          'GarageFinish', 'GarageQual', 'GarageCond', 'Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature']].info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the information shown in the previous cell, it can be seen that some variables that are related to basement still have nulls/missing data. Let's study the rows with nulls further."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get the rows that has nulls or missing data for basement-related variables\ndf_clean[df_clean[['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType2']].isnull().any(axis=1)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the rows of data shown above, it can be observed that all the nulls in these variables actually represent missing data, instead of indicating that these variables are not possessed by the house. Missing data will be handled during Exploratory Data Analysis. Therefore, the objective of this particular cleaning process is achieved."},{"metadata":{},"cell_type":"markdown","source":"#### Step 3: Match the values of 'Exterior1st' and 'Exterior2nd'\n\n***Define***\n\nChange 'Wd Shng' in 'Exterior2nd' to 'WdShing' ('Exterior1st') and 'Brk Cmn' in 'Exterior2nd' to 'BrkComm' ('Exterior1st')\n\n***Code***"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace 'Wd Shng' in 'Exterior2nd' with 'WdShing'\ndf_clean['Exterior2nd'] = df_clean['Exterior2nd'].replace('Wd Shng', 'WdShing') \n\n# Replace 'Brk Cmn' in 'Exterior2nd' with 'BrkComm'\ndf_clean['Exterior2nd'] = df_clean['Exterior2nd'].replace('Brk Cmn', 'BrkComm') ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Test***"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean['Exterior2nd'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Step 4: Fix values of year-related variables\n\n***Define***\n\n- For rows with ID of 523, YearRemodAdd doesn't occur between YearBuilt and YrSold. YearRemodAdd should be replaced with YearBuilt or YrSold, depending on which is closer to YearRemodAdd\n\n- For rows with IDs of 29, 93, 324, 600, 736, 1103, 1376, 1414 and 1418, GarageYrBlt doesn't occur between YearBuilt and YrSold. GarageYrBlt should be replaced with YearBuilt or YrSold, depending on which is closer to GarageYrBlt\n\n***Code***"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Code for the first item in the list above\n\n# Define the IDs to work on\nids_for_remod = 523\n\nyear_built = df.loc[ids_for_remod, 'YearBuilt']\nyear_sold = df.loc[ids_for_remod, 'YrSold']\nyear_remod_add = df.loc[ids_for_remod, 'YearRemodAdd']\n    \n# Compute absolute difference between YearBuilt and YearRemodAdd\ndiff_built_remod = abs(year_built - year_remod_add)\n    \n# Compute absolute difference between YearSold and YearRemodAdd\ndiff_sold_remod = abs(year_sold - year_remod_add)\n    \n# YearRemodAdd should is replaced with YearBuilt or YrSold, depending on which is closer to YearRemodAdd\ndf_clean.loc[ids_for_remod, 'YearRemodAdd'] = year_built if diff_built_remod <= diff_sold_remod else year_sold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Code for the second item in the list above\n\n# Define the IDs to work on\nids_for_garage = [29, 93, 324, 600, 736, 1103, 1376, 1414, 1418]\n\nfor row_id in ids_for_garage:\n    year_built = df.loc[row_id, 'YearBuilt']\n    year_sold = df.loc[row_id, 'YrSold']\n    year_garage_built = df.loc[row_id, 'GarageYrBlt']\n    \n    # Compute absolute difference between YearBuilt and YearRemodAdd\n    diff_built_garage = abs(year_built - year_garage_built)\n    \n    # Compute absolute difference between YearSold and YearRemodAdd\n    diff_sold_garage = abs(year_sold - year_garage_built)\n    \n    \n    df_clean.loc[row_id, 'GarageYrBlt'] = year_built if diff_built_garage <= diff_sold_garage else year_sold","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Test***"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test for the first item in the list above\ndf_clean.loc[[ids_for_remod] , ['YearBuilt', 'YearRemodAdd', 'YrSold']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test for the second item in the list above\ndf_clean.loc[ids_for_garage , ['YearBuilt', 'GarageYrBlt', 'YrSold']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Step 5: Drop variables with too many missing data\n\n***Define***\n\n- Drop Alley, FireplaceQu, PoolQC, Fence and MiscFeature from the data frame due to too many missing data\n\n***Code***"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define columns to be dropped\ncols = ['Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature']\n\ndf_clean = df_clean.drop(cols, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Test***"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verify that columns are dropped from the data frame\nprint(set(cols) & set(df_clean.columns))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Saving <a class=\"anchor\" id=\"saving\"></a>\n\nAfter data wrangling is completed, the cleaned data frame is saved to a CSV file"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save cleaned dataframe to a CSV file\ndf_clean.to_csv('train_cleaned.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}